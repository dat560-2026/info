{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSOEkREmQSe8"
      },
      "source": [
        "# DAT560: Generative AI\n",
        "\n",
        "* Lectures: Vinay Setty, Petra Galuscakova.\n",
        "* Teaching Assistant: Gabriel Iturra-Bocaz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YzoYSJzH6Ch"
      },
      "source": [
        "## Colab\n",
        "Google Colab is a research tool for teaching and research in Machine Learning. It is a **Jupyter notebook** environment that does not require configuration for its use. Colab offers a free **cloud GPU** service hosted by Google to encourage collaboration in the field of Machine Learning, without worrying about hardware requirements. Colab was released to the public by Google in October 2017."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDuk4lFegB8f"
      },
      "source": [
        "## GPU\n",
        "In Colab, you will get **12 hours of runtime**, but the session will disconnect if it is inactive for more than 60 minutes. This means that every 12 hours, the disk, RAM, CPU cache memory and the data located on our assigned virtual machine will be **wiped**.\n",
        "\n",
        "To enable the use of the GPU hardware accelerator, you only need to go to **Runtime -> Change runtime type -> Hardware accelerator -> GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqASP2gcrZsf",
        "outputId": "436df0dc-7ba4-4267-8503-afb9d5289358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Jan  9 09:31:19 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eytPOlerYV2",
        "outputId": "8a8176f5-253b-4001-9929-c78a6aed7f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "memory.total [MiB], memory.used [MiB], memory.free [MiB]\n",
            "15360 MiB, 0 MiB, 15095 MiB\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buIf0fcvrpi-"
      },
      "source": [
        "## RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwroe-mPr5JN",
        "outputId": "ccd3b2ba-e18d-4c3c-f487-f82b49d2004a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       721Mi       8.5Gi       3.0Mi       3.5Gi        11Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ],
      "source": [
        "!free -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jny2zyWixPVT"
      },
      "source": [
        "## Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOw2r_iYsDEN",
        "outputId": "78df9fb1-4d95-4a5a-ca08-7bd37c47b930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "total           220G   81G  139G  37% -\n"
          ]
        }
      ],
      "source": [
        "!df -h --total | grep Filesystem\n",
        "!df -h --total | grep total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzVt72s5KekT"
      },
      "source": [
        "## Install PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0FbN_DiKXiG"
      },
      "outputs": [],
      "source": [
        "# Currently installed PyTorch version: 2.9.0+cu126\n",
        "# You can verify this by running `torch.__version__` in a code cell.\n",
        "\n",
        "# Installing Pytorch version 2.3.1 with CUDA 12.1\n",
        "#!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Installing Pytorch version 2.3.1 without CUDA (CPU only)\n",
        "#!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NJKA-RsKDaz"
      },
      "source": [
        "# Pytorch\n",
        "It provides two fundamental characteristics:\n",
        "1. n-dimensional Tensor, similar to Numpy but they can be stored on GPUs\n",
        "2. automatic differentiation for training Neural Networks\n",
        "\n",
        "## Installation\n",
        "Pytorch is installed on the Colab virtual machine. But if you want to run this notebook in another environment, you may need to install it. At https://pytorch.org/ you can find a complete guide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88BjGz5La6Ba"
      },
      "source": [
        "## Importing PyTorch and other packages\n",
        "First, we will import the required libraries. Remember that torch, numpy and matplotlib are pre-installed on the Colab virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjMNP3R_a4f1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gyJk3XsDFl62",
        "outputId": "ba67ec23-08ef-4aec-fc62-faff9fe09076"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.9.0+cu126'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDGbpn2gXOQe"
      },
      "source": [
        "## Tensor\n",
        "Operations based on Numpy are not optimized to use the GPU and accelerate their numerical calculations. For modern deep neural networks, GPUs often provide speedups of 50x or more. So, unfortunately, numpy will not be sufficient for modern deep learning. This is where Pytorch introduces the concept of Tensor. A Pytorch tensor is conceptually identical to an n-dimensional numpy array. The difference is that PyTorch tensors can use the GPU to accelerate their numerical calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjYL5YAeMZsN"
      },
      "source": [
        "In PyTorch the default tensor type is **float** defined as **torch.FloatTensor**. We can create tensors using the **built-in functions** within the package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mE64px7NZ1s",
        "outputId": "9a75df90-f8fa-4237-af9d-a832cf72036b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a=\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "b=\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "## creating a tensor of 3 rows and 2 columns consisting of ones\n",
        "a = torch.ones(3,2)\n",
        "\n",
        "## creating a tensor of 3 rows and 2 columns consisting of zeros\n",
        "b = torch.zeros(3,2)\n",
        "\n",
        "print('a=\\n{}'.format(a))\n",
        "print('b=\\n{}'.format(b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJiuUxVOcEs5"
      },
      "source": [
        "We can create tensors **from Python lists or sequences** using the `torch.tensor()` constructor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kRqKUuXczyA",
        "outputId": "619aff56-fc34-4909-cd3f-2341ee7cee50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a=\n",
            "tensor([[ 1., -1.],\n",
            "        [-1.,  1.]])\n",
            "b=\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1., -1.], [-1., 1.]])\n",
        "b = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n",
        "\n",
        "print('a=\\n{}'.format(a))\n",
        "print('b=\\n{}'.format(b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4do0hVbvN4FP"
      },
      "source": [
        "Random **initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsvHPhhnOEIz",
        "outputId": "0da1650c-0db6-499e-a5be-9525084a5ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a=\n",
            "tensor([[0.6147, 0.3810],\n",
            "        [0.6371, 0.4745],\n",
            "        [0.7136, 0.6190]])\n",
            "b=\n",
            "tensor([[-2.1409, -0.5534, -0.5000],\n",
            "        [-0.0815, -0.1633,  1.5277],\n",
            "        [-0.4023,  0.0972, -0.5682]])\n"
          ]
        }
      ],
      "source": [
        "#to increase the reproducibility, we often set the random seed to a specific value first.\n",
        "torch.manual_seed(2)\n",
        "\n",
        "#generating tensor randomly from uniform distribution on the interval [0, 1)\n",
        "a = torch.rand(3, 2)\n",
        "\n",
        "#generating tensor randomly from standar normal distribution (mean 0 and variance 1)\n",
        "b = torch.randn(3, 3)\n",
        "\n",
        "print('a=\\n{}'.format(a))\n",
        "print('b=\\n{}'.format(b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-y-wmGKUQsa"
      },
      "source": [
        "## PyTorch <--> numpy\n",
        "Converting a PyTorch tensor to a numpy `ndarray` can be convenient sometimes. By using `.numpy()` on a tensor we can easily convert the tensor to an `ndarray`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71OB_OVdU44w",
        "outputId": "caa0161c-ee13-4ffc-e326-442f0e4ded07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
            "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x = torch.linspace(0, 1, steps = 5)  # creating a tensor using linspace\n",
        "print(x)\n",
        "x_np = x.numpy()  # convert tensor to numpy\n",
        "print(type(x), type(x_np))  # check the types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7u8IYkyVUuY"
      },
      "source": [
        "To convert from an `ndarray` to a `tensor`, we can use `.from_numpy()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZHwbeG0Vqin",
        "outputId": "cb43d4a0-62ef-4e2d-eee5-0ab5dcc0c73f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.07207252  1.21023881  0.08487561 -0.08669264 -2.91734876]\n",
            "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "x = np.random.randn(5)  # generate a random numpy array\n",
        "print(x)\n",
        "x_pt = torch.from_numpy(x)  # convert numpy array to a tensor\n",
        "print(type(x), type(x_pt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzEd3_PHNjPy"
      },
      "source": [
        "An important point to note is that PyTorch tensors don't share their memory with the objects that were used to create them. This is illustrated below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjwCQem8N-YZ",
        "outputId": "4b80c34c-7b54-4443-a789-88e2f85915bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4]\n",
            "[10  1  2  3  4]\n",
            "tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "x = np.arange(5)\n",
        "\n",
        "# Transform to a PyTorch tensor\n",
        "x_tensor = torch.tensor(x)\n",
        "\n",
        "# Print the original numpy array\n",
        "print(x)\n",
        "\n",
        "# Change a value from the original array\n",
        "x[0] = 10\n",
        "\n",
        "# Print the original value and the Pytorch tensor\n",
        "print(x)\n",
        "print(x_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY-Zi7ebPKmX"
      },
      "source": [
        "On the other hand, the `torch.tensor()` method presented earlier copies the data. Therefore it does not have this behavior. From the method documentation:\n",
        "\n",
        "*torch.tensor() always copies data.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFlM-1x2WCEs"
      },
      "source": [
        "## CUDA\n",
        "To check how many CUDA-compatible GPUs are connected to the machine, you can use the code snippet below. If you are running the code in Colab you will get `1`, which means that the Colab virtual machine is connected to a GPU. `torch.cuda` is used to set up and perform CUDA operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oztGCyHUWihQ",
        "outputId": "715be4b8-c741-490e-9447-496608a21ce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(torch.cuda.device_count())\n",
        "  print(torch.cuda.get_device_name(0))  # name of the first GPU Card connected to the machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koUFk8piXe-N"
      },
      "source": [
        "The important thing to keep in mind is that we can reference this CUDA-compatible GPU card from a variable and use it for any PyTorch operation. All CUDA tensors you allocate will be created on that device. The selected GPU device can be changed using a context manager `torch.cuda.device`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG5bHphZXOh7",
        "outputId": "319a65d6-56d3-4343-dcff-5dc3a2a919e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[7., 7.],\n",
            "        [7., 7.],\n",
            "        [7., 7.]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Assign cuda GPU located at location '0' to a variable\n",
        "cuda0 = torch.device('cuda:0')\n",
        "\n",
        "# Performing the addition on GPU\n",
        "a = torch.ones(3, 2, device=cuda0)  # creating a tensor 'a' on GPU 0\n",
        "b = torch.ones(3, 2, device=cuda0)  # creating a tensor 'b' on GPU 0\n",
        "# b = torch.ones(3, 2)  # creating a tensor 'b' on GPU 0\n",
        "c = a + b + 5\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xPPL2ErYpsl"
      },
      "source": [
        "If you want to move the result to the CPU, you just have to use `.cpu()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msmpvAERYtu_",
        "outputId": "2c450cbf-5066-4634-f5bc-2b960615020f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[7., 7.],\n",
            "        [7., 7.],\n",
            "        [7., 7.]])\n",
            "tensor([[7., 7.],\n",
            "        [7., 7.],\n",
            "        [7., 7.]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "c = c.cpu()\n",
        "print(c)\n",
        "c = c.cuda()\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA0CU_DkTO8A"
      },
      "source": [
        "It is important to note that a tensor located on the GPU cannot be operated on with one whose device is CPU. This is one of the most common errors you will encounter during your assignments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "yTH8XhWoTBkK",
        "outputId": "c09f4b77-1597-4d5e-ace1-8e73956f718c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "cpu\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1613275968.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "a = torch.ones(3, 2, device='cuda')\n",
        "b = torch.ones(3, 2)\n",
        "\n",
        "print(a.device)\n",
        "print(b.device)\n",
        "c = a + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8kusXdKTnHj"
      },
      "source": [
        "Another very common error, similar to the previous one, is trying to operate with tensors of different types. This is shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "w5gGuPYQTuLA",
        "outputId": "27b605b5-2ffc-484c-fb4f-b9c15c62427b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.int64\n",
            "torch.float32\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "expected m1 and m2 to have the same dtype, but got: long int != float",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1370780605.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: long int != float"
          ]
        }
      ],
      "source": [
        "a = torch.ones(3, 2).long()\n",
        "b = torch.ones(2, 3).float()\n",
        "\n",
        "print(a.dtype)\n",
        "print(b.dtype)\n",
        "\n",
        "c = a @ b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObMriFD3sn-I"
      },
      "source": [
        "### Checking computation time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEHtjCOZswRe",
        "outputId": "569c9e5c-c6ef-44e1-f83e-df776f206b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mm in CPU...\n",
            "CPU time = 24.96701428900002\n",
            "mm in GPU...\n",
            "GPU time = 0.3044821980000165\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "size_matrix = 10000\n",
        "x = torch.randn((size_matrix, size_matrix))\n",
        "y = torch.randn((size_matrix, size_matrix))\n",
        "\n",
        "# CPU\n",
        "print('mm in CPU...')\n",
        "start = time.perf_counter()\n",
        "z = torch.mm(x,y)\n",
        "total_time = time.perf_counter() - start\n",
        "print('CPU time = {}'.format(total_time))\n",
        "\n",
        "# GPU\n",
        "print('mm in GPU...')\n",
        "start = time.perf_counter()\n",
        "z = torch.mm(x.cuda(),y.cuda())\n",
        "total_time = time.perf_counter() - start\n",
        "print('GPU time = {}'.format(total_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUajudUNOaue"
      },
      "source": [
        "## Simple operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfn7N73SOok8"
      },
      "source": [
        "### Slicing\n",
        "We can slice PyTorch tensors in the same way as with `ndarray`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puWNqYX0OZqO",
        "outputId": "6861cc6a-cd44-4a40-eca7-8ba562334b28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 4, 6])\n",
            "tensor([1, 2])\n",
            "tensor(4)\n"
          ]
        }
      ],
      "source": [
        "# create a tensor\n",
        "x = torch.tensor([[1, 2],\n",
        "                 [3, 4],\n",
        "                 [5, 6]])\n",
        "\n",
        "print(x[:, -1]) # every elements in dim 0, only last element in dim 1\n",
        "print(x[0, :])  # only first elements in dim 0, every elements in dim 1\n",
        "print(x[1, 1])  # take the 2nd element in dim 0 and 2nd element in dim 1. Create another tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDJU8tI3QC8h"
      },
      "source": [
        "### Reshape\n",
        "Change the shape of a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFfJoiWOQTcK",
        "outputId": "725c4aeb-ece6-495b-ecca-93329c0d4984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "size of x: torch.Size([3, 2])\n",
            "size of dim 1: 2\n",
            "x=\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "y=\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "y=\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n"
          ]
        }
      ],
      "source": [
        "# get size of tensor\n",
        "x_size = x.size()\n",
        "print('size of x: {}'.format(x_size))\n",
        "\n",
        "x_dim1 = x.size(1)\n",
        "print('size of dim 1: {}'.format(x_dim1))\n",
        "\n",
        "# print the original x\n",
        "print('x=\\n{}'.format(x))\n",
        "\n",
        "# reshape\n",
        "y = x.view(2, 3)\n",
        "print('y=\\n{}'.format(y))\n",
        "\n",
        "# transpose\n",
        "y = y.transpose(0, 1)\n",
        "print('y=\\n{}'.format(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXJH-4QXQri6"
      },
      "source": [
        "#### Using `-1` when resizing tensors\n",
        "`-1` indicates that the dimension will be deduced from the previous dimensions. In the code snippet below `x.view(-1, 18)` will result in a tensor of shape 2x18 because we have set the size of the second dimension to 18. Pytorch **will infer the size** of the first dimension so that it is able to accommodate all the values present in the tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p-s7ICZRZGo",
        "outputId": "10ca2537-eb01-4ad5-8e88-713836eb53c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = \n",
            "tensor([[ 0.4067,  1.1428,  1.1395,  0.3312, -0.4058,  1.5398],\n",
            "        [-1.0269, -0.3457,  0.7173,  0.1219, -2.1880, -0.0339],\n",
            "        [-1.2026,  0.0442,  1.2448,  0.5142,  0.9545, -0.2788],\n",
            "        [-1.0429, -0.6653,  0.5834, -0.1013, -0.3938,  1.0776],\n",
            "        [-0.7612, -1.6493,  0.2493,  1.1304,  0.0758, -0.4449],\n",
            "        [ 0.0168, -0.4787, -0.6460, -0.9951, -1.3670, -0.9369]])\n",
            "y1 =\n",
            "torch.Size([2, 18])\n",
            "y2 =\n",
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(6, 6)\n",
        "y1 = x.view(-1, 18)\n",
        "y2 = x.view(2, 6, -1)\n",
        "# y2 = x.view(2, 5, -1)  # Error because shape '[2, 5, -1]' is invalid for input of size 36\n",
        "\n",
        "print(\"x = \\n{}\".format(x))\n",
        "print(\"y1 =\\n{}\".format(y1.size()))\n",
        "print(\"y2 =\\n{}\".format(y2.size()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z65p9v5pSq7E"
      },
      "source": [
        "## Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OVlkr7mS4iu",
        "outputId": "f1505879-8471-4239-ab8c-15e6250aa969"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "add=\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]]) ok\n",
            "sub=\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]]) ok\n",
            "mul=\n",
            "tensor([[6., 6.],\n",
            "        [6., 6.],\n",
            "        [6., 6.]]) ok\n",
            "mm=\n",
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.],\n",
            "        [2., 2., 2.]]) ok\n",
            "dot= 14.0 ok\n"
          ]
        }
      ],
      "source": [
        "# create three tensors\n",
        "x = torch.ones(3, 2)\n",
        "y = torch.ones(3, 2)\n",
        "\n",
        "# adding two tensors (element-wise)\n",
        "z1 = x + y            # method 1\n",
        "z2 = torch.add(x, y)  # method 2\n",
        "print('add=\\n{}'.format(z1), 'ok' if torch.all(z1 == z2) else 'wrong')\n",
        "\n",
        "# subtracting two tensors (element-wise)\n",
        "z1 = x - y            # method 1\n",
        "z2 = torch.sub(x, y)  # method 2\n",
        "print('sub=\\n{}'.format(z1), 'ok' if torch.all(z1 == z2) else 'wrong')\n",
        "\n",
        "# multiplying two tensors (element-wise)\n",
        "z1 = (x + 1) * (y + 2)        # method 1\n",
        "z2 = torch.mul(x + 1, y + 2)  # method 2\n",
        "print('mul=\\n{}'.format(z1), 'ok' if torch.all(z1 == z2) else 'wrong')\n",
        "\n",
        "# matrix multiplication\n",
        "z1 = x @ y.view(2, 3)           # method 1\n",
        "z2 = torch.mm(x, y.view(2, 3))  # method 2\n",
        "print('mm=\\n{}'.format(z1), 'ok' if torch.all(z1 == z2) else 'wrong')\n",
        "\n",
        "# dot product, the result is a scalar\n",
        "z1 = torch.Tensor([4, 2]) @ torch.Tensor([3, 1])           # method 1\n",
        "z2 = torch.dot(torch.Tensor([4, 2]), torch.Tensor([3, 1])) # method 2\n",
        "print('dot= {}'.format(z1), 'ok' if torch.all(z1 == z2) else 'wrong')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CBbqcuGTMUy"
      },
      "source": [
        "### Inplace\n",
        "In Pytorch, all operations on tensors that operate in-place will have a `_` as a postfix. For example, `add` is the out-of-place version and `add_` is the in-place version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDP2hZgOTOaZ",
        "outputId": "b135fd3c-9a2b-4cc0-fb82-d5ea974eb3e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n"
          ]
        }
      ],
      "source": [
        "y.add_(x)  # tensor y added with x and result will be stored in y\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-UNJsgVotXa"
      },
      "source": [
        "## Broadcasting in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT3dAnGjpJxf"
      },
      "source": [
        "Many operations in PyTorch support [NumPy Broadcasting Semantics](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html#module-numpy.doc.broadcasting).\n",
        "\n",
        "If a PyTorch operation supports broadcasting, its arguments (tensors) can be automatically expanded so that they are of the same size (**without making copies of the data**). *It is nothing more than a way of doing element-wise operations on tensors that do not necessarily have the same dimensions.*\n",
        "\n",
        "Two tensors are \"broadcastable\" if:\n",
        "1. Each tensor has at least one dimension.\n",
        "2. When iterating over the sizes of the dimensions (starting from the final dimension), their sizes must be equal, one of them is `1` or one of them does not exist.\n",
        "\n",
        "If two tensors are \"broadcastable\" the dimensions of the resulting tensor are determined by:\n",
        "1. If the number of dimensions is not equal, `1` is prepended to the dimensions of the tensor with fewer dimensions so that they have the same length.\n",
        "2. Then, for each dimension size, the resulting dimension size is the maximum of the sizes in that dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6MX4Rvs2fby",
        "outputId": "63377730-870f-4da6-8aed-0406fe930cf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z= tensor([4.8085, 4.4823, 4.8047])\n",
            "z= torch.Size([5, 7, 3])\n",
            "z= torch.Size([5, 3, 4, 1])\n",
            "z= torch.Size([10, 10])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(3)\n",
        "z = x + 4  # sum the scalar to each element\n",
        "print('z= {}'.format(z))\n",
        "\n",
        "x = torch.randn(5,7,3)\n",
        "y = torch.randn(5,7,3)\n",
        "z = x + y  # same shapes are always broadcastable\n",
        "print('z= {}'.format(z.size()))\n",
        "\n",
        "x = torch.randn(5,3,4,1)\n",
        "y = torch.randn(  3,1,1)\n",
        "z = x + y\n",
        "print('z= {}'.format(z.size()))\n",
        "# x and y are broadcastable.\n",
        "# 1st trailing dimension: both have size 1\n",
        "# 2nd trailing dimension: y has size 1\n",
        "# 3rd trailing dimension: x size == y size\n",
        "# 4th trailing dimension: y dimension doesn't exist\n",
        "\n",
        "x = torch.rand(1,10)\n",
        "y = torch.rand(10,1)\n",
        "z = x + y\n",
        "print('z= {}'.format(z.size()))\n",
        "\n",
        "# NOT broadcastables examples:\n",
        "\n",
        "# x = torch.randn(3,2)\n",
        "# y = torch.randn(  3)\n",
        "# z = x + y  # Error in the 1st trailing dimension 2 != 3\n",
        "\n",
        "# x = torch.empty((0,))\n",
        "# y = torch.empty(2,2)\n",
        "# z = x + y  # Error because x does not have at least 1 dimension\n",
        "\n",
        "# x=torch.empty(5,2,4,1)\n",
        "# y=torch.empty(  3,1,1)\n",
        "# z = x + y  # Error because in the 3rd trailing dimension 2 != 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12s9Q3qS3zL7"
      },
      "source": [
        "**Be careful**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKMMVk6GJ7OW"
      },
      "source": [
        "## Defining the network parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qafEEhqwKE4x",
        "outputId": "b29a5059-3b3b-49dc-a182-452bffb68747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyModule(\n",
            "  (_MyModule__hiddens): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 200x200]\n",
            "      (1): Parameter containing: [torch.float32 of size 200x200]\n",
            "      (2): Parameter containing: [torch.float32 of size 200x200]\n",
            "      (3): Parameter containing: [torch.float32 of size 200x200]\n",
            "      (4): Parameter containing: [torch.float32 of size 200x200]\n",
            "  )\n",
            ")\n",
            "Count of parameters: 7\n",
            "tensor([[1.]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyModule(nn.Module):\n",
        "    def __init__(self, in_size, h_size, out_size, levels):\n",
        "        super(MyModule, self).__init__()\n",
        "        self.__in = nn.Parameter(torch.rand(in_size, h_size))\n",
        "        self.__hiddens = nn.ParameterList([nn.Parameter(torch.rand(h_size, h_size)) for i in range(levels)])\n",
        "        self.__out = nn.Parameter(torch.rand(h_size, out_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x.mm(self.__in)\n",
        "\n",
        "        # ParameterList can act as an iterable, or be indexed using ints\n",
        "        for hidden in self.__hiddens:\n",
        "            h = h.mm(hidden)\n",
        "\n",
        "        y = torch.sigmoid(h.mm(self.__out))\n",
        "        return y\n",
        "\n",
        "net = MyModule(in_size=128, h_size=200, out_size=1, levels=5)\n",
        "print(net)\n",
        "print('Count of parameters: {}'.format(len(list(net.parameters()))))\n",
        "\n",
        "x = torch.ones(1, 128)\n",
        "print(net(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEOxYob8RKzQ"
      },
      "source": [
        "## Dataset, DataLoader and batches\n",
        "`Dataset` is an abstract class that represents a data set.\n",
        "\n",
        "All data sets that represent a key->target map should be subclasses of `Dataset`. All subclasses must override `__getitem__()`, which allows retrieving a data sample for a given k. Subclasses may also optionally override `__len__()`, which is expected to return the size of the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPSLSStsSoze",
        "outputId": "d934d30e-5d07-49a2-f67f-397ab93eb1c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 0: torch.Size([100, 1])\n",
            "iter 1: torch.Size([100, 1])\n",
            "iter 2: torch.Size([100, 1])\n",
            "iter 3: torch.Size([100, 1])\n",
            "iter 4: torch.Size([100, 1])\n",
            "iter 5: torch.Size([100, 1])\n",
            "iter 6: torch.Size([100, 1])\n",
            "iter 7: torch.Size([100, 1])\n",
            "iter 8: torch.Size([100, 1])\n",
            "iter 9: torch.Size([100, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch.utils.data as data\n",
        "\n",
        "class MyDataset(data.Dataset):\n",
        "  def __init__(self, vectors, targets):\n",
        "    self.vectors = vectors\n",
        "    self.targets = targets\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return vectors[index], targets[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(vectors)\n",
        "\n",
        "# generate random data\n",
        "import random\n",
        "odds = list(range(0, 10000, 2))\n",
        "evens = list(range(1, 10000, 2))\n",
        "vectors = [torch.FloatTensor([random.sample(odds if i%2==0 else evens, 128)]) for i in range(1000)]\n",
        "targets = [i%2==0 for i in range(1000)]\n",
        "\n",
        "# create Dataset\n",
        "dataset = MyDataset(vectors, targets)\n",
        "\n",
        "# define data loader by batchs\n",
        "loader = data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "# define net model\n",
        "net = MyModule(128, 200, 1, 2)\n",
        "\n",
        "# itering over batchs\n",
        "for i, (x, y) in enumerate(loader):\n",
        "  # (batch_size x 1 x 128) -> (batch_size x 128)\n",
        "  x = x.view(-1, 128)\n",
        "\n",
        "  # compute predictions\n",
        "  prediction = net(x)\n",
        "\n",
        "  print('iter {}: {}'.format(i, prediction.size()))\n",
        "\n",
        "  # here you are going to compute accuracy, loss and update weights\n",
        "  # ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNf9VQ5blUlf"
      },
      "source": [
        "## Differentiation\n",
        "The Leaky rectified linear unit (Leaky ReLU) activation function is defined as :\n",
        "\n",
        "$$ f(x) =\n",
        "\\left\\{\n",
        "    \\begin{array}{ll}\n",
        "        x  & \\mbox{if } x \\geq 0 \\\\\n",
        "        \\alpha \\cdot x & \\mbox{if } x < 0\n",
        "    \\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Therefore its derivative will be:\n",
        "$$ \\frac{d\\,f}{dx}(x) =\n",
        "\\left\\{\n",
        "    \\begin{array}{ll}\n",
        "        1  & \\mbox{if } x \\geq 0 \\\\\n",
        "        \\alpha & \\mbox{if } x < 0\n",
        "    \\end{array}\n",
        "\\right.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHfQg1_DlTll",
        "outputId": "2abeaad4-9b5a-4467-97c4-a47a836ffd91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = tensor([[ 0.4951,  2.5643,  0.9044, -1.7103, -1.7591]])\n",
            "leaky_relu(x, 0.1) = tensor([[1.0000, 1.0000, 1.0000, 0.1000, 0.1000]])\n"
          ]
        }
      ],
      "source": [
        "def leaky_relu(x, alpha, gradient = False):\n",
        "  if gradient:\n",
        "    y = torch.ones_like(x)\n",
        "    y[x < 0]  = alpha\n",
        "    return y\n",
        "\n",
        "  y = x\n",
        "  y[y < 0] = alpha * y[y < 0]\n",
        "\n",
        "  return y\n",
        "\n",
        "x = torch.randn(1,5)\n",
        "print(\"x = {}\".format(x))\n",
        "\n",
        "leaky_relu = leaky_relu(x, 0.1, gradient=True)\n",
        "print(\"leaky_relu(x, 0.1) = {}\".format(leaky_relu))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmmwPcVfY73a"
      },
      "source": [
        "## Automatic differentiation\n",
        "The `autograd` package gives us the ability to perform automatic differentiation or automatic gradient computation for all operations on tensors. It is a define-by-run framework, which means that our back-propagation is defined by how our code is executed.\n",
        "\n",
        "Let's see how to perform automatic differentiation through a simple example. First, we create a tensor with the `requires_grad` parameter set to `True` because we want to track all the operations performed on that tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKyIDCnDZ4Ud",
        "outputId": "ac8f708b-11b5-42b7-b14d-acf741390b5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "tensor([[6., 6.],\n",
            "        [6., 6.],\n",
            "        [6., 6.]], grad_fn=<AddBackward0>)\n",
            "tensor([[37., 37.],\n",
            "        [37., 37.],\n",
            "        [37., 37.]], grad_fn=<AddBackward0>)\n",
            "tensor(222., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# create a tensor with requires_grad = True\n",
        "x = torch.ones([3,2], requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# perform a simple tensor addition operation\n",
        "y = x + 5  # tensor addition\n",
        "print(y)  # check the result\n",
        "\n",
        "# perform more operations on y and create a new tensor z\n",
        "z = y*y + 1\n",
        "print(z)\n",
        "\n",
        "t = torch.sum(z)  # adding all the values in z\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8yE2q5DaA-x"
      },
      "source": [
        "From the expressions above, we have:\n",
        "\n",
        "$z = (x + 5)^{2} + 1$\n",
        "\n",
        "We also know that $t$ corresponds to the sum of the values of $z$ for each of its positions. But the derivative at each position remains the same (due to the derivative of the sum). Then we can calculate:\n",
        "\n",
        "$\\frac{dz}{dx} = 2\\times (x + 5)$\n",
        "\n",
        "Therefore:\n",
        "\n",
        "$\\frac{dz}{dx}(1) = 2\\times (1 + 5) = 12$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQF-jSXia3ju"
      },
      "source": [
        "### Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kgWeT1xbJYa",
        "outputId": "a2a00158-b6bf-4c7e-e743-be0138f792fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[12., 12.],\n",
            "        [12., 12.],\n",
            "        [12., 12.]])\n"
          ]
        }
      ],
      "source": [
        "t.backward() #peform backpropagation but pytorch will not print any output.\n",
        "\n",
        "# print gradients d(t)/dx\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFZ9dt82tXJe"
      },
      "source": [
        "## SGD\n",
        "Gradient Descent, or Stochastic Gradient Descent, is an optimization algorithm to update the parameters of the machine learning model. There are many other update algorithms (called optimizers), but SGD is simpler and easier to implement.\n",
        "\n",
        "For this optimizer we need a learning rate, generally a small floating number. This will be a constant (at least in SGD) that will reflect how abruptly we will be updating the network parameters. The larger it is, the more we change in each iteration; the smaller, the more subtle the change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhXtntXgtV6A",
        "outputId": "2b38fa69-9c83-4ca3-9647-67585e7d8c44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our tensor before the update:\n",
            " tensor([[0.3109],\n",
            "        [0.1274]], requires_grad=True)\n",
            "\n",
            "The output: tensor([[-0.3667]], grad_fn=<MmBackward0>)\n",
            "\n",
            "Our tensor after the update:\n",
            " tensor([[0.3101],\n",
            "        [0.1580]], requires_grad=True)\n",
            "\n",
            "The output after the update: tensor([[-0.4607]])\n"
          ]
        }
      ],
      "source": [
        "# Lets set the learning rate to 0.5\n",
        "lr = 0.01\n",
        "epochs = 100\n",
        "\n",
        "# We generate 2 random tensors. One 1x2 and another 2x1\n",
        "x = torch.randn(1,2, dtype=torch.float)\n",
        "y = torch.randn(2,1)\n",
        "\n",
        "# we need to explicitly tell pytorch that we want this tensor to hace its gradients calculated\n",
        "y.requires_grad_()\n",
        "print(f\"Our tensor before the update:\\n {y}\")\n",
        "\n",
        "# Multiply the input tensor with our middle tensor\n",
        "z = x @ y\n",
        "print(\"\\nThe output: {}\".format(z))\n",
        "\n",
        "# calculate the gradients\n",
        "z.backward()\n",
        "\n",
        "# this is just an indicator to pytorch to not listen to the following operations\n",
        "# if we dont use this, the gradient could change unexpectedly\n",
        "with torch.no_grad():\n",
        "    y -= y.grad * lr  # update the tensor with the learning rate and its gradient\n",
        "    y.grad.zero_()  # set the gradient to zero, we dont want this to accumulate\n",
        "    print(f\"\\nOur tensor after the update:\\n {y}\")\n",
        "    z = x @ y\n",
        "    print(\"\\nThe output after the update: {}\".format(z))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPeaPj7vM3-6"
      },
      "source": [
        "# Training a Feed-Forward Network for Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "n1cEsbz9M097"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4jHqeujFM-9f"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),     # small images\n",
        "    transforms.ToTensor(),           # [0,1]\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPJ2NVB6TdhE"
      },
      "source": [
        "##  Dataset\n",
        "\n",
        "\n",
        "We use the Oxford-IIIT Pet dataset, which is available directly through torchvision.datasets.\n",
        "\n",
        "This dataset contains:\n",
        "\n",
        "* Images of 37 pet breeds\n",
        "\n",
        "* Both cats and dogs\n",
        "\n",
        "* High-quality, real-world photographs\n",
        "\n",
        "For this notebook, we simplify the task to binary classification:\n",
        "\n",
        "* 0  Cat\n",
        "\n",
        "* 1  Dog\n",
        "\n",
        "PyTorch allows us to request this binary setup using target_types=\"binary-category\".\n",
        "\n",
        "The dataset is split into:\n",
        "\n",
        "* Training set (trainval): used to train the neural network\n",
        "\n",
        "* Test set (test): used to evaluate how well the model generalizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhEgTd5ANEss",
        "outputId": "de6ec0d4-6977-4cc6-dfd9-7a77cd74fbfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 792M/792M [00:27<00:00, 28.4MB/s]\n",
            "100%|| 19.2M/19.2M [00:01<00:00, 13.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.OxfordIIITPet(\n",
        "    root=\"./data\",\n",
        "    split=\"trainval\",\n",
        "    target_types=\"binary-category\",\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_dataset = datasets.OxfordIIITPet(\n",
        "    root=\"./data\",\n",
        "    split=\"test\",\n",
        "    target_types=\"binary-category\",\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bmfm6BYTa1m"
      },
      "source": [
        "Each sample consists of:\n",
        "\n",
        "An RGB image tensor of shape (3, H, W)\n",
        "\n",
        "A binary label indicating whether the image is a cat or a dog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "LF7jnmqUOcKg",
        "outputId": "25055e0c-7fde-482b-b65d-5678f6ad0220"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Random indices\n",
        "train_idx = random.randint(0, len(train_dataset) - 1)\n",
        "test_idx = random.randint(0, len(test_dataset) - 1)\n",
        "\n",
        "# Get samples\n",
        "train_img, train_label = train_dataset[train_idx]\n",
        "test_img, test_label = test_dataset[test_idx]\n",
        "\n",
        "# Convert from (C, H, W)  (H, W, C) for matplotlib\n",
        "train_img = train_img.permute(1, 2, 0)\n",
        "test_img = test_img.permute(1, 2, 0)\n",
        "\n",
        "label_map = {0: \"Cat\", 1: \"Dog\"}\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "axes[0].imshow(train_img)\n",
        "axes[0].set_title(f\"Train sample (idx={train_idx}): {label_map[train_label]}\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(test_img)\n",
        "axes[1].set_title(f\"Test sample (idx={test_idx}): {label_map[test_label]}\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnnUFIUITn43"
      },
      "source": [
        "##  DataLoader\n",
        "\n",
        "A Dataset in PyTorch represents the data itself. Its role is to define how individual samples are stored and accessed. It knows how many examples exist and how to return one sample at a time (for example, one image and its label). A Dataset does not handle batching, shuffling, or performance optimizationsit simply answers the question: What is sample i?\n",
        "\n",
        "A DataLoader is needed to efficiently feed data to the model during training. It wraps a Dataset and automatically creates mini-batches, shuffles the data each epoch, and loads samples in parallel to avoid I/O bottlenecks. Without a DataLoader, training would be slower, more error-prone, and require manual batching logic. In practice, models are almost always trained using a DataLoader rather than accessing the Dataset directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P8WNbR9BNkDE"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iASi8lgiTwtO"
      },
      "source": [
        "## Feed-Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ily8wXzpNn7p"
      },
      "outputs": [],
      "source": [
        "class FeedForwardNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(64 * 64 * 3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)   # binary output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # flatten\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySjCmV0oT1Z_"
      },
      "source": [
        "## Training Setup\n",
        "\n",
        "\n",
        "Here we set up the training configuration, including the device where tensors and operations will be executed, and we define the model, loss function, and optimizer.\n",
        "\n",
        "For the optimizer, PyTorch provides several options in the [```optim ```](https://docs.pytorch.org/docs/stable/optim.html) module, allowing you to choose different optimization strategies depending on the problem and training behavior you want.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U8wRGx7fNs08"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = FeedForwardNet().to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuBHfRU6T3Je"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "The following training loop shows how the model learns by repeatedly processing the training data, computing errors, and updating its parameters over multiple epochs.\n",
        "\n",
        "**Epoch**: One epoch means one full pass over the entire training dataset. Here, the model sees all training samples 5 times.\n",
        "\n",
        "### Train steps\n",
        "\n",
        "* `model.train()`: Puts the model in training mode (important for layers like dropout or batch normalization).\n",
        "\n",
        "* Iterate over `train_loader`: Loads the training data in mini-batches.\n",
        "\n",
        "* `images.to(device), labels.to(device)`: Moves data to the same device (CPU or GPU) as the model.\n",
        "\n",
        "* `optimizer.zero_grad()`: Clears old gradients from the previous update step.\n",
        "\n",
        "* `outputs = model(images)`: Performs a forward pass to get predictions.\n",
        "\n",
        "* `loss = criterion(outputs, labels)`: Computes how wrong the predictions are.\n",
        "\n",
        "* `loss.backward()`: Computes gradients via backpropagation.\n",
        "\n",
        "* `optimizer.step()`: Updates the model parameters using those gradients.\n",
        "\n",
        "* `total_loss += loss.item()`: Accumulates loss to monitor training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkEPzQK5NwK_",
        "outputId": "2909d473-1a96-428c-aef8-86f92f315683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Loss: 0.6666\n",
            "Epoch 2 | Loss: 0.6337\n",
            "Epoch 3 | Loss: 0.6321\n",
            "Epoch 4 | Loss: 0.6336\n",
            "Epoch 5 | Loss: 0.6228\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Loss: {total_loss / len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb2_l35ST9p3"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "\n",
        "After training, it is important to evaluate the model to understand how well it generalizes to unseen data and to ensure it has not simply memorized the training set. For this task, we use **classification accuracy** as the evaluation metric, which measures the proportion of correctly predicted cat and dog images and provides an intuitive and easy-to-interpret indicator of model performance for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPw30fwyN3hJ",
        "outputId": "5fbcbf67-8021-44ab-cf02-9a8d7133c7e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.677\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).squeeze()\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(f\"Test accuracy: {correct / total:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIz9sojhsXqL"
      },
      "source": [
        "# References\n",
        "* Pytorch documentation: https://pytorch.org/docs/stable/index.html\n",
        "* A tutorial on how autograd works: https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
